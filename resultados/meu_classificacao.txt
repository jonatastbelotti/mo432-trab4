Arquivo de entrada: ./dados4.csv com 5581 registros
Foram corrigidos 62 registros nulos

====================================================================================================
Número de entradas -> 1
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.481243, 0.464158)
Regressão Logística com Regularização L2: C=0.012851297805926299, max_iter=200, penalty=l2 -> (0.484110, 0.465950)
LDA:  -> (0.481243, 0.464158)
QDA:  -> (0.494146, 0.467742)
SVM Linear: C=14134.700048883094 -> (0.510155, 0.514337)
SVM com kernel RBF: C=44.21353086194267, gamma=0.013843080680966659, kernel=rbf -> (0.497730, 0.478495)
Naive Bayes:  -> (0.494385, 0.467742)
KNN: n_neighbors=232 -> (0.501075, 0.521505)
MLP: hidden_layer_sizes=90, max_iter=400 -> (0.499642, 0.512545)
Arvore de decisão: ccp_alpha=0.00018600842338637236 -> (0.507288, 0.478495)
GBM: learning_rate=0.1852574265650584, max_depth=5, n_estimators=81 -> (0.511350, 0.480287)


Tempo execução: 6.04 minutos
Melhor modelo: KNN
Parâmetros: n_neighbors=232
Score conjunto medida: 0.521505



====================================================================================================
Número de entradas -> 2
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.483014, 0.473118)
Regressão Logística com Regularização L2: C=0.012851297805926299, max_iter=200, penalty=l2 -> (0.483732, 0.460573)
LDA:  -> (0.483014, 0.473118)
QDA:  -> (0.494258, 0.474910)
SVM Linear: C=892.8000970176704 -> (0.502153, 0.478495)
SVM com kernel RBF: C=9335.556863228498, gamma=0.013843080680966659, kernel=rbf -> (0.498565, 0.519713)
Naive Bayes:  -> (0.494498, 0.473118)
KNN: n_neighbors=43 -> (0.500478, 0.498208)
MLP: hidden_layer_sizes=185, max_iter=400 -> (0.498565, 0.521505)
Arvore de decisão: ccp_alpha=0.00018600842338637236 -> (0.508612, 0.483871)
GBM: learning_rate=0.20715021041486617, max_depth=5, n_estimators=64 -> (0.505742, 0.487455)


Tempo execução: 7.13 minutos
Melhor modelo: MLP
Parâmetros: hidden_layer_sizes=185, max_iter=400
Score conjunto medida: 0.521505



====================================================================================================
Número de entradas -> 3
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.483493, 0.460573)
Regressão Logística com Regularização L2: C=0.012851297805926299, max_iter=200, penalty=l2 -> (0.484689, 0.465950)
LDA:  -> (0.483254, 0.460573)
QDA:  -> (0.495215, 0.483871)
SVM Linear: C=99.99794321036585 -> (0.504785, 0.478495)
SVM com kernel RBF: C=44.21353086194267, gamma=0.01506574227915343, kernel=rbf -> (0.498565, 0.501792)
Naive Bayes:  -> (0.495215, 0.483871)
KNN: n_neighbors=88 -> (0.502632, 0.507168)
MLP: hidden_layer_sizes=145, max_iter=400 -> (0.500000, 0.521505)
Arvore de decisão: ccp_alpha=0.00014238902172478252 -> (0.500000, 0.491039)
GBM: learning_rate=0.20715021041486617, max_depth=3, n_estimators=69 -> (0.511722, 0.501792)


Tempo execução: 7.55 minutos
Melhor modelo: MLP
Parâmetros: hidden_layer_sizes=145, max_iter=400
Score conjunto medida: 0.521505



====================================================================================================
Número de entradas -> 4
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.491627, 0.465950)
Regressão Logística com Regularização L2: C=0.14683721985793594, max_iter=200, penalty=l2 -> (0.491866, 0.467742)
LDA:  -> (0.491627, 0.465950)
QDA:  -> (0.493780, 0.482079)
SVM Linear: C=458.67548772145426 -> (0.514593, 0.521505)
SVM com kernel RBF: C=44.21353086194267, gamma=0.01506574227915343, kernel=rbf -> (0.499043, 0.508961)
Naive Bayes:  -> (0.493780, 0.480287)
KNN: n_neighbors=88 -> (0.498325, 0.523297)
MLP: hidden_layer_sizes=95, max_iter=400 -> (0.500239, 0.535842)
Arvore de decisão: ccp_alpha=0.00014238902172478252 -> (0.497608, 0.485663)
GBM: learning_rate=0.22836124778228453, max_depth=5, n_estimators=81 -> (0.494019, 0.530466)


Tempo execução: 8.13 minutos
Melhor modelo: MLP
Parâmetros: hidden_layer_sizes=95, max_iter=400
Score conjunto medida: 0.535842



====================================================================================================
Número de entradas -> 5
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.488995, 0.469534)
Regressão Logística com Regularização L2: C=2.041445839528077, max_iter=200, penalty=l2 -> (0.488995, 0.469534)
LDA:  -> (0.488995, 0.469534)
QDA:  -> (0.495455, 0.476703)
SVM Linear: C=14134.700048883094 -> (0.510287, 0.478495)
SVM com kernel RBF: C=587.7065234122807, gamma=0.004636332418932946, kernel=rbf -> (0.499282, 0.512545)
Naive Bayes:  -> (0.495694, 0.476703)
KNN: n_neighbors=209 -> (0.501196, 0.514337)
MLP: hidden_layer_sizes=75, max_iter=400 -> (0.499282, 0.503584)
Arvore de decisão: ccp_alpha=0.00014238902172478252 -> (0.494258, 0.487455)
GBM: learning_rate=0.20715021041486617, max_depth=5, n_estimators=97 -> (0.497847, 0.480287)


Tempo execução: 8.43 minutos
Melhor modelo: KNN
Parâmetros: n_neighbors=209
Score conjunto medida: 0.514337



====================================================================================================
Número de entradas -> 6
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.491627, 0.449821)
Regressão Logística com Regularização L2: C=2.041445839528077, max_iter=200, penalty=l2 -> (0.491627, 0.449821)
LDA:  -> (0.491866, 0.449821)
QDA:  -> (0.495694, 0.467742)
SVM Linear: C=458.67548772145426 -> (0.509809, 0.478495)
SVM com kernel RBF: C=3.1001528008323973, gamma=0.03403157900825344, kernel=rbf -> (0.499282, 0.519713)
Naive Bayes:  -> (0.495933, 0.467742)
KNN: n_neighbors=209 -> (0.500478, 0.512545)
MLP: hidden_layer_sizes=35, max_iter=400 -> (0.499043, 0.519713)
Arvore de decisão: ccp_alpha=0.023063704382964498 -> (0.486364, 0.478495)
GBM: learning_rate=0.1852574265650584, max_depth=3, n_estimators=81 -> (0.494737, 0.519713)


Tempo execução: 8.59 minutos
Melhor modelo: SVM com kernel RBF
Parâmetros: C=3.1001528008323973, gamma=0.03403157900825344, kernel=rbf
Score conjunto medida: 0.519713



====================================================================================================
Número de entradas -> 7
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.496172, 0.462366)
Regressão Logística com Regularização L2: C=0.012851297805926299, max_iter=200, penalty=l2 -> (0.497129, 0.462366)
LDA:  -> (0.496411, 0.462366)
QDA:  -> (0.493062, 0.456989)
SVM Linear: C=4503.8686112857495 -> (0.510048, 0.478495)
SVM com kernel RBF: C=0.31559390577752605, gamma=0.03403157900825344, kernel=rbf -> (0.499522, 0.501792)
Naive Bayes:  -> (0.493062, 0.456989)
KNN: n_neighbors=209 -> (0.499522, 0.512545)
MLP: hidden_layer_sizes=70, max_iter=400 -> (0.496411, 0.521505)
Arvore de decisão: ccp_alpha=0.00018600842338637236 -> (0.498804, 0.525090)
GBM: learning_rate=0.22836124778228453, max_depth=5, n_estimators=97 -> (0.503828, 0.512545)


Tempo execução: 8.68 minutos
Melhor modelo: Arvore de decisão
Parâmetros: ccp_alpha=0.00018600842338637236
Score conjunto medida: 0.525090



====================================================================================================
Número de entradas -> 8
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.485269, 0.460573)
Regressão Logística com Regularização L2: C=2.041445839528077, max_iter=200, penalty=l2 -> (0.485269, 0.460573)
LDA:  -> (0.485269, 0.460573)
QDA:  -> (0.496287, 0.460573)
SVM Linear: C=458.67548772145426 -> (0.506347, 0.521505)
SVM com kernel RBF: C=3.1001528008323973, gamma=0.01506574227915343, kernel=rbf -> (0.501557, 0.507168)
Naive Bayes:  -> (0.496287, 0.460573)
KNN: n_neighbors=261 -> (0.501557, 0.516129)
MLP: hidden_layer_sizes=20, max_iter=400 -> (0.499641, 0.500000)
Arvore de decisão: ccp_alpha=0.00014238902172478252 -> (0.492934, 0.494624)
GBM: learning_rate=0.20040040533240522, max_depth=3, n_estimators=19 -> (0.498683, 0.498208)


Tempo execução: 8.83 minutos
Melhor modelo: SVM Linear
Parâmetros: C=458.67548772145426
Score conjunto medida: 0.521505



====================================================================================================
Número de entradas -> 9
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.485988, 0.465950)
Regressão Logística com Regularização L2: C=2.041445839528077, max_iter=200, penalty=l2 -> (0.485988, 0.465950)
LDA:  -> (0.485988, 0.464158)
QDA:  -> (0.495090, 0.456989)
SVM Linear: C=458.67548772145426 -> (0.507545, 0.517921)
SVM com kernel RBF: C=3.1001528008323973, gamma=0.01506574227915343, kernel=rbf -> (0.501078, 0.510753)
Naive Bayes:  -> (0.494850, 0.456989)
KNN: n_neighbors=232 -> (0.502275, 0.514337)
MLP: hidden_layer_sizes=25, max_iter=400 -> (0.497725, 0.519713)
Arvore de decisão: ccp_alpha=0.023063704382964498 -> (0.486946, 0.478495)
GBM: learning_rate=0.20040040533240522, max_depth=5, n_estimators=81 -> (0.498443, 0.471326)


Tempo execução: 9.01 minutos
Melhor modelo: MLP
Parâmetros: hidden_layer_sizes=25, max_iter=400
Score conjunto medida: 0.519713



====================================================================================================
Número de entradas -> 10
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.488383, 0.462366)
Regressão Logística com Regularização L2: C=2.041445839528077, max_iter=200, penalty=l2 -> (0.488383, 0.462366)
LDA:  -> (0.488383, 0.462366)
QDA:  -> (0.494850, 0.462366)
SVM Linear: C=99.99794321036585 -> (0.498443, 0.478495)
SVM com kernel RBF: C=0.31559390577752605, gamma=0.03403157900825344, kernel=rbf -> (0.500120, 0.517921)
Naive Bayes:  -> (0.494611, 0.462366)
KNN: n_neighbors=232 -> (0.504910, 0.519713)
MLP: hidden_layer_sizes=5, max_iter=400 -> (0.504431, 0.489247)
Arvore de decisão: ccp_alpha=0.00014238902172478252 -> (0.488862, 0.523297)
GBM: learning_rate=0.048429106763381295, max_depth=4, n_estimators=25 -> (0.495329, 0.521505)


Tempo execução: 9.17 minutos
Melhor modelo: Arvore de decisão
Parâmetros: ccp_alpha=0.00014238902172478252
Score conjunto medida: 0.523297



====================================================================================================
Número de entradas -> 11
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.491976, 0.462366)
Regressão Logística com Regularização L2: C=0.14683721985793594, max_iter=200, penalty=l2 -> (0.492455, 0.458781)
LDA:  -> (0.491976, 0.462366)
QDA:  -> (0.497246, 0.456989)
SVM Linear: C=458.67548772145426 -> (0.502994, 0.516129)
SVM com kernel RBF: C=16312.49639436731, gamma=3.1202981216411563, kernel=rbf -> (0.499641, 0.532258)
Naive Bayes:  -> (0.497246, 0.456989)
KNN: n_neighbors=232 -> (0.505150, 0.525090)
MLP: hidden_layer_sizes=50, max_iter=400 -> (0.500359, 0.521505)
Arvore de decisão: ccp_alpha=0.00018600842338637236 -> (0.496527, 0.469534)
GBM: learning_rate=0.15574345454843158, max_depth=3, n_estimators=97 -> (0.506108, 0.489247)


Tempo execução: 10.58 minutos
Melhor modelo: SVM com kernel RBF
Parâmetros: C=16312.49639436731, gamma=3.1202981216411563, kernel=rbf
Score conjunto medida: 0.532258



====================================================================================================
Número de entradas -> 12
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.489341, 0.462366)
Regressão Logística com Regularização L2: C=0.012851297805926299, max_iter=200, penalty=l2 -> (0.490060, 0.464158)
LDA:  -> (0.489581, 0.462366)
QDA:  -> (0.496048, 0.456989)
SVM Linear: C=99.99794321036585 -> (0.510180, 0.521505)
SVM com kernel RBF: C=0.31559390577752605, gamma=0.03403157900825344, kernel=rbf -> (0.501317, 0.517921)
Naive Bayes:  -> (0.496527, 0.456989)
KNN: n_neighbors=209 -> (0.497485, 0.525090)
MLP: hidden_layer_sizes=30, max_iter=400 -> (0.500599, 0.544803)
Arvore de decisão: ccp_alpha=0.00014238902172478252 -> (0.494850, 0.521505)
GBM: learning_rate=0.20040040533240522, max_depth=3, n_estimators=97 -> (0.502754, 0.507168)


Tempo execução: 9.63 minutos
Melhor modelo: MLP
Parâmetros: hidden_layer_sizes=30, max_iter=400
Score conjunto medida: 0.544803



====================================================================================================
Número de entradas -> 13
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.492455, 0.453405)
Regressão Logística com Regularização L2: C=0.14683721985793594, max_iter=200, penalty=l2 -> (0.493174, 0.453405)
LDA:  -> (0.492455, 0.453405)
QDA:  -> (0.496527, 0.478495)
SVM Linear: C=4503.8686112857495 -> (0.511138, 0.478495)
SVM com kernel RBF: C=0.31559390577752605, gamma=0.03403157900825344, kernel=rbf -> (0.502036, 0.516129)
Naive Bayes:  -> (0.496766, 0.478495)
KNN: n_neighbors=454 -> (0.497725, 0.537634)
MLP: hidden_layer_sizes=55, max_iter=400 -> (0.503713, 0.507168)
Arvore de decisão: ccp_alpha=0.00014238902172478252 -> (0.488383, 0.492832)
GBM: learning_rate=0.20040040533240522, max_depth=5, n_estimators=97 -> (0.497006, 0.508961)


Tempo execução: 9.98 minutos
Melhor modelo: KNN
Parâmetros: n_neighbors=454
Score conjunto medida: 0.537634



====================================================================================================
Número de entradas -> 14
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.496643, 0.469534)
Regressão Logística com Regularização L2: C=2.041445839528077, max_iter=200, penalty=l2 -> (0.496882, 0.469534)
LDA:  -> (0.496643, 0.469534)
QDA:  -> (0.497362, 0.478495)
SVM Linear: C=99.99794321036585 -> (0.501918, 0.521505)
SVM com kernel RBF: C=0.31559390577752605, gamma=0.03403157900825344, kernel=rbf -> (0.499041, 0.500000)
Naive Bayes:  -> (0.497602, 0.478495)
KNN: n_neighbors=454 -> (0.500480, 0.535842)
MLP: hidden_layer_sizes=20, max_iter=400 -> (0.500719, 0.521505)
Arvore de decisão: ccp_alpha=0.00014238902172478252 -> (0.497602, 0.508961)
GBM: learning_rate=0.22836124778228453, max_depth=5, n_estimators=64 -> (0.499281, 0.546595)


Tempo execução: 10.10 minutos
Melhor modelo: GBM
Parâmetros: learning_rate=0.22836124778228453, max_depth=5, n_estimators=64
Score conjunto medida: 0.546595



====================================================================================================
Número de entradas -> 15
O PCA deixou 1 atributos
Regressão Logística (sem regularização):  -> (0.496643, 0.478495)
Regressão Logística com Regularização L2: C=0.012851297805926299, max_iter=200, penalty=l2 -> (0.496882, 0.478495)
LDA:  -> (0.496643, 0.478495)
QDA:  -> (0.498801, 0.478495)
SVM Linear: C=892.8000970176704 -> (0.510312, 0.478495)
SVM com kernel RBF: C=0.31559390577752605, gamma=0.03403157900825344, kernel=rbf -> (0.499760, 0.501792)
Naive Bayes:  -> (0.498561, 0.478495)
KNN: n_neighbors=261 -> (0.501199, 0.525090)
MLP: hidden_layer_sizes=105, max_iter=400 -> (0.500959, 0.517921)
Arvore de decisão: ccp_alpha=0.00014238902172478252 -> (0.497362, 0.494624)
GBM: learning_rate=0.1852574265650584, max_depth=5, n_estimators=69 -> (0.497602, 0.525090)


Tempo execução: 10.65 minutos
Melhor modelo: KNN
Parâmetros: n_neighbors=261
Score conjunto medida: 0.525090


====================================================================================================
====================================================================================================
====================================================================================================
Tempo execução: 2.21 horas
Melhor número entradas: 14
Melhor modelo: GBM
Melhores parâmetros: learning_rate=0.22836124778228453, max_depth=5, n_estimators=64
Melhor acurária conjunto medida: 0.546595
